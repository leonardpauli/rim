// filterExpression/lexemUtils.js
// LayerRenamer
//
// created by Leonard Pauli, jun 2018
// copyright Â© Leonard Pauli 2018
//
// based on rim / towards rim

import sfo, {log} from 'string-from-object'
import {objectMapRecursive} from '../object'
const concat = xxs=> xxs.reduce((a, xs)=> (a.push(...xs), a), [])


// Philosofy:
// 	- expressions should always parse, syntax errors reported back + skipped gracefully, warnings auto fixed (+ reported back)
// 	- parsed code should always be evaluatable


// lexems flags

export const flags = {
	// autoInsertIfNeeded: true, // if no other paths are valid, insert token even if it didn't exist, useful for eg. autoclose
	optional: true,
	repeat: true, // is one or more (+) by default, combine repeat + optional to get 0 or more (*)
	usingOr: true,
}
export const astidFlags = {
	prefix: true,
	suffix: true,
	infix: true,
}

// TODO: separate type and instance

// lexems example
const keysMeta = 'name,description,type'.split(',') // on .type
const keysMatch = 'regex,retain,lexems,usingOr'.split(',') // on .type
const keysTokenizerReserved = 'matched,match,location,tokens,lexems'.split(',')
const keysAst = 'astValueGet,lexemsAstTypes,astValue,astTokens,astId,astTokenWrapperIs,astTokenNot'.split(',')
export const keysReserved = concat([keysMeta, keysMatch, keysTokenizerReserved, keysAst, Object.keys(flags)])

/*
// (could probably use prototype/classes instead but nah, want to optimise for easy move to rim)
const lexem = {}
const lexemMatch = {
	regex: /^((g1)|(g2))/,
	retain: true, // true (all), n (retain n chars), -n (retain match.length-n chars), false | 0 (retain no chars)
} || {
	...{usingOr: true}||{lexemsModeAnd: false}, // match one of them || match all of them after each other (default)
	lexems: [lexem, lexem, ...lexem],
}
const lexemBase = {
	name: '...', // autogenerated from lexems tree structure, eg. text.expr.open
	description: 'what this lexem is...',
	someSubLexem: lexem,
}
const lexemExample = { ...lexemBase, ...lexemMatch, ...flags }
*/

export const lexemIs = v=> !!(v && v.type) // TODO: use symbol instead? (add in validate, export + check existance here)

export const lexemExtendCopyClean1Level = l=> ({
	...l.type===l? {type: l}: {...l},
	matched: void 0, match: void 0, location: {s: 0, e: 0}, // s=start, e=end
	tokens: void 0, lexems: void 0,
	astTokens: void 0, astValue: void 0,
})


// process lexems
const lexemTypeValidateFix = lt=> { // lexem type
	if (!lt.name) throw new Error(
		`lexem(${sfo(lt, 2)}).name not set`)

	if (lt.regex) {
		if (!(lt.regex instanceof RegExp)) throw new Error(
			`lexem(${lt.name}).regex (should be) instanceof RegExp (was ${lt.regex})`)
		if (''.match(lt.regex)) throw new Error(
			`lexem(${lt.name}).regex(${lt.regex}) matches zero length, please fix (or mod tokenizer, see TODO in tests)`)
		lt.retain = lt.retain === void 0? true: lt.retain===false? 0: lt.retain
	} else if (lt.lexems) {
		if (!Array.isArray(lt.lexems)) throw new Error(
			`lexem(${lt.name}).lexems has to be array`)
		lt.usingOr = lt.usingOr || false
		if (lt.usingOr && lt.lexems.some(l=> l.optional)) throw new Error(
			`lexem(${lt.name}).lexems has one optional, not allowed + ambiguos/doesn't make sense when usingOr`)
	} else throw new Error(
		`lexem(${lt.name}) has to have a matcher (.regex/.lexems)`)
}

const _process = (lexem, k, parent=null, state={named: new Set(), noname: new Set()})=> {
	lexem.type = lexem.type || lexem
	const {type} = lexem

	// process meta
	type.name = type.name || (parent && parent.name+'.' || '')+k
	state.named.add(type)

	// validate matcher + set defaults
	lexemTypeValidateFix(type)
	if (type.lexems) type.lexems.forEach((l, k)=>
		!l.name && state.noname.add([l, k, type]))

	// process children
	const keysChildren = Object.keys(type).filter(k=> !keysReserved.includes(k))
	keysChildren.forEach(k=> type[k] = _process(type[k], k, type, state))

	return lexem
}

const recursivelyFixNestedLexems = ([lexem, k, parent])=> {
	lexem.type = lexem.type || lexem
	const {type} = lexem

	if (!type.name) {
		type.name = (parent && parent.name+'.' || '')+k
		type.lexems && type.lexems.forEach((l, k)=> type.lexems[k] = recursivelyFixNestedLexems([l, k, type]))
	}
	lexemTypeValidateFix(type)
	return lexem
}

export const expand = root=> {
	if (Array.isArray(root)) throw new Error(
		`expand got array lexem, expected object, please wrap like {lexems: [<array-lexem>]}`)
	const state = {named: new Set(), noname: new Set()}
	_process(root, root.name || '@', null, state)
	state.noname.forEach(([lexem, k, parent])=> parent.lexems[k] =
		recursivelyFixNestedLexems([lexem, k, parent]))
	// intermediate lexems = named through recursivelyAddNameToLexems
	// all lexems = state.named + intermediate lexems
}


// TODO: do in lexems ast pre-processor?
export const astidsExpand = astids=>
	Object.keys(astids).map(k=> astids[k].name = astids[k].name || k)
export const lexemsAstTypesExpand = types=> types.forEach((p, i)=> p.prio = i)


export const lexemSimplifyForView = o=> objectMapRecursive(o, (v, k, {recurse})=>
		v && v.type && v.type === v? `${v.type.name}`
	: v && typeof v==='object' && !(v.constructor===Object || Array.isArray(v))? v
	: recurse? recurse()
	: v)

export const lexemAstValueToPlain = v=> objectMapRecursive(v, (v, k, {recurse})=>
	recurse? recurse(): v, {
	beforeMap: obj=> obj.type && obj.type===obj.type.type
		?	{type: obj.type.name, astValue: obj.astValue}
		: obj,
})
